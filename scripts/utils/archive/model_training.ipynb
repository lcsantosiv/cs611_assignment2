{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c4b374e-1f2c-4142-8741-3ce0863ba220",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "libgomp.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score, roc_curve\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/__init__.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# .basic is intentionally loaded as early as possible, to dlopen() lib_lightgbm.{dll,dylib,so}\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# and its dependencies as early as possible\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Booster, Dataset, Sequence, register_logger\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallback\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopException, early_stopping, log_evaluation, record_evaluation, reset_parameter\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CVBooster, cv, train\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/basic.py:9\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for C API of LightGBM.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This import causes lib_lightgbm.{dll,dylib,so} to be loaded.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# It's intentionally done here, as early as possible, to avoid issues like\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# \"libgomp.so.1: cannot allocate memory in static TLS block\" on aarch64 Linux.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# For details, see the \"cannot allocate memory in static TLS block\" entry in docs/FAQ.rst.\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlibpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _LIB  \u001b[38;5;66;03m# isort: skip\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mabc\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mctypes\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/lightgbm/libpath.py:49\u001b[0m\n\u001b[1;32m     47\u001b[0m     _LIB \u001b[38;5;241m=\u001b[39m Mock(ctypes\u001b[38;5;241m.\u001b[39mCDLL)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m     _LIB \u001b[38;5;241m=\u001b[39m \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcdll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLoadLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_find_lib_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/ctypes/__init__.py:451\u001b[0m, in \u001b[0;36mLibraryLoader.LoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLoadLibrary\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dlltype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/ctypes/__init__.py:373\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: libgomp.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import mlflow.lightgbm\n",
    "from typing import Dict, Any, List\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "def load_data_for_training(spark: SparkSession, feature_store_path: str, label_store_path: str, weeks: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"Loads feature and label data for a given list of week partitions and joins them.\"\"\"\n",
    "    \n",
    "    feature_paths = [os.path.join(feature_store_path, f\"feature_store_week_{week}\") for week in weeks]\n",
    "    label_paths = [os.path.join(label_store_path, f\"label_store_week_{week}\") for week in weeks]\n",
    "    \n",
    "    features_df = spark.read.parquet(*feature_paths)\n",
    "    labels_df = spark.read.parquet(*label_paths)\n",
    "    \n",
    "    # The 'id' column is the key to join features and labels\n",
    "    final_df = features_df.join(labels_df, \"id\")\n",
    "    \n",
    "    return final_df.toPandas()\n",
    "\n",
    "def train_and_tune_model(training_df: pd.DataFrame, model_type: str = 'xgboost'):\n",
    "    \"\"\"\n",
    "    Trains and tunes a model (XGBoost or LightGBM) using Hyperopt.\n",
    "    Logs all parameters, metrics, and the model artifact to MLflow.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate features (X) and target (y)\n",
    "    X = training_df.drop(columns=['id', 'grade', 'snapshot_date'])\n",
    "    y = training_df['grade'].apply(lambda x: 1 if x in ['D', 'E', 'F', 'G'] else 0) # Example binary target\n",
    "    \n",
    "    # Split data into training and validation for hyperparameter tuning\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    def objective(params):\n",
    "        with mlflow.start_run(nested=True):\n",
    "            if model_type == 'xgboost':\n",
    "                model = xgb.XGBClassifier(**params, use_label_encoder=False, eval_metric='logloss')\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=30, verbose=False)\n",
    "            elif model_type == 'lightgbm':\n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "                model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=30, verbose=-1)\n",
    "\n",
    "            y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "            auc = roc_auc_score(y_val, y_pred_proba)\n",
    "            \n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_metric(\"validation_auc\", auc)\n",
    "            \n",
    "            # Hyperopt minimizes the loss, so we return 1 - AUC\n",
    "            return {'loss': 1 - auc, 'status': STATUS_OK}\n",
    "\n",
    "    if model_type == 'xgboost':\n",
    "        search_space = {\n",
    "            'n_estimators': hp.quniform('n_estimators', 100, 1000, 50),\n",
    "            'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "            'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "            'subsample': hp.uniform('subsample', 0.7, 1.0),\n",
    "            'colsample_bytree': hp.uniform('colsample_bytree', 0.7, 1.0),\n",
    "        }\n",
    "    elif model_type == 'lightgbm':\n",
    "         search_space = {\n",
    "            'n_estimators': hp.quniform('n_estimators', 100, 1000, 50),\n",
    "            'learning_rate': hp.loguniform('learning_rate', -3, 0),\n",
    "            'num_leaves': hp.quniform('num_leaves', 20, 150, 1),\n",
    "            'max_depth': hp.quniform('max_depth', 3, 10, 1),\n",
    "        }\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"Tune_{model_type}\"):\n",
    "        trials = Trials()\n",
    "        best_params = fmin(\n",
    "            fn=objective,\n",
    "            space=search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=20, # Increase for more thorough search\n",
    "            trials=trials\n",
    "        )\n",
    "        \n",
    "        # Log the best parameters found\n",
    "        mlflow.log_params(best_params)\n",
    "        \n",
    "        # Train final model on full data with best parameters\n",
    "        if model_type == 'xgboost':\n",
    "            final_model = xgb.XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
    "            mlflow.xgboost.log_model(final_model, f\"{model_type}-model\")\n",
    "        elif model_type == 'lightgbm':\n",
    "            final_model = lgb.LGBMClassifier(**best_params)\n",
    "            mlflow.lightgbm.log_model(final_model, f\"{model_type}-model\")\n",
    "            \n",
    "        final_model.fit(X, y) # Fit on all data\n",
    "        \n",
    "        # You can log other artifacts like feature importance plots here\n",
    "        print(f\"Finished training for {model_type}. Best validation AUC: {1 - trials.best_trial['result']['loss']:.4f}\")\n",
    "\n",
    "def calculate_psi(expected: pd.Series, actual: pd.Series, buckets: int = 10) -> float:\n",
    "    \"\"\"Calculate the Population Stability Index (PSI) for a single variable.\"\"\"\n",
    "    \n",
    "    # Create bins based on the 'expected' distribution\n",
    "    breakpoints = pd.unique(np.percentile(expected, [i * 100 / buckets for i in range(buckets + 1)]))\n",
    "    \n",
    "    expected_percents = pd.cut(expected, bins=breakpoints, retbins=False, labels=False).value_counts(normalize=True)\n",
    "    actual_percents = pd.cut(actual, bins=breakpoints, retbins=False, labels=False).value_counts(normalize=True)\n",
    "\n",
    "    # Align the series to ensure we have the same bins\n",
    "    expected_percents, actual_percents = expected_percents.align(actual_percents, join='outer', fill_value=0)\n",
    "    \n",
    "    # Add a small epsilon to avoid division by zero\n",
    "    expected_percents = expected_percents.replace(0, 0.0001)\n",
    "    actual_percents = actual_percents.replace(0, 0.0001)\n",
    "\n",
    "    psi_values = (actual_percents - expected_percents) * np.log(actual_percents / expected_percents)\n",
    "    \n",
    "    return np.sum(psi_values)\n",
    "\n",
    "def run_oot_monitoring(oot_df: pd.DataFrame, training_df_for_psi: pd.DataFrame, model_uri: str):\n",
    "    \"\"\"\n",
    "    Performs OOT validation on a model from the MLflow Registry.\n",
    "    Calculates AUC, KS, and PSI.\n",
    "    \"\"\"\n",
    "    # Load the production model\n",
    "    production_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    \n",
    "    # Prepare OOT data\n",
    "    X_oot = oot_df.drop(columns=['id', 'grade', 'snapshot_date'])\n",
    "    y_oot = oot_df['grade'].apply(lambda x: 1 if x in ['D', 'E', 'F', 'G'] else 0)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_proba = production_model.predict(X_oot)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    oot_auc = roc_auc_score(y_oot, y_pred_proba)\n",
    "    \n",
    "    # Calculate PSI on the model score\n",
    "    training_scores = production_model.predict(training_df_for_psi.drop(columns=['id', 'grade', 'snapshot_date']))\n",
    "    score_psi = calculate_psi(pd.Series(training_scores), pd.Series(y_pred_proba))\n",
    "\n",
    "    with mlflow.start_run(run_name=\"OOT_Validation\"):\n",
    "        mlflow.log_metric(\"oot_auc\", oot_auc)\n",
    "        mlflow.log_metric(\"oot_score_psi\", score_psi)\n",
    "        print(f\"OOT AUC: {oot_auc:.4f}, Score PSI: {score_psi:.4f}\")\n",
    "\n",
    "    return {\"oot_auc\": oot_auc, \"oot_score_psi\": score_psi} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3368bd27-4f17-42a0-b75a-c6f9bb62ad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lightgbm in /home/airflow/.local/lib/python3.8/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/airflow/.local/lib/python3.8/site-packages (from lightgbm) (1.24.4)\n",
      "Requirement already satisfied: scipy in /home/airflow/.local/lib/python3.8/site-packages (from lightgbm) (1.10.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install lightgbm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
